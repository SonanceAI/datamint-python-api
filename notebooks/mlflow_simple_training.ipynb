{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea9bc4f",
   "metadata": {},
   "source": [
    "# MLflow Simple Training Tutorial\n",
    "\n",
    "This notebook demonstrates how to train a semantic segmentation model using Datamint's MLflow integration. You'll learn how to:\n",
    "\n",
    "- Set up your environment and configure MLflow\n",
    "- Load and visualize data from Datamint\n",
    "- Define data transformations for training\n",
    "- Train a model with automatic MLflow logging\n",
    "- Test the model and register it in the model registry\n",
    "- Make predictions with the trained model\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have:\n",
    "1. Datamint Python API installed (`pip install git+https://github.com/Sonance/datamint-python-api.git`)\n",
    "2. Your API key configured (run `datamint-config` in terminal)\n",
    "3. Access to a project with segmentation data\n",
    "4. Basic understanding of PyTorch and/or PyTorch Lightning\n",
    "\n",
    "## What is MLflow?\n",
    "\n",
    "MLflow is an open-source platform for managing machine learning workflows. It helps you:\n",
    "- Track experiments (metrics, parameters, code versions)\n",
    "- Package and reproduce models\n",
    "- Deploy models to production\n",
    "- Manage model versions in a central registry\n",
    "\n",
    "Datamint provides seamless MLflow integration, automatically configuring tracking and artifact storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07325547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Environment Setup\n",
    "# ========================\n",
    "\n",
    "# Import datamint.mlflow to automatically configure MLflow environment\n",
    "# This sets up MLflow tracking URI and authentication based on your Datamint configuration\n",
    "import datamint.mlflow\n",
    "from datamint import APIHandler\n",
    "import logging\n",
    "import rich.logging\n",
    "\n",
    "logging.getLogger().addHandler(rich.logging.RichHandler())\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "LOGGER.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Initialize Datamint API handler to verify connection\n",
    "# This will use your configured API key (set via `datamint-config` command)\n",
    "api = APIHandler()\n",
    "LOGGER.info(\"✅ Datamint API connection established successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ef3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Project Configuration\n",
    "# =============================\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from datamint.mlflow import set_project\n",
    "\n",
    "# IMPORTANT: Replace 'BoneSeg' with your actual project name\n",
    "PROJECT_NAME = 'BoneSeg' # you can retrieve project names using `api.get_projects()`\n",
    "\n",
    "# Set the active project for MLflow tracking\n",
    "# This ensures all experiments are logged under the correct project\n",
    "project_info = set_project(PROJECT_NAME)\n",
    "LOGGER.info(f\"✅ Active project set to: {project_info['name']}\")\n",
    "LOGGER.info(f\"Description: {project_info.get('description', 'No description')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456d53e",
   "metadata": {},
   "source": [
    "## Data Transformations\n",
    "\n",
    "Data augmentation is crucial for training robust models. We'll use Albumentations library to define transformations that:\n",
    "\n",
    "- **Resize and crop**: Standardize input size while maintaining aspect ratio\n",
    "- **Symmetry**: Apply square symmetry for anatomical consistency  \n",
    "- **Color jitter**: Vary brightness/contrast to handle different imaging conditions\n",
    "- **Gaussian noise**: Add robustness to image artifacts\n",
    "\n",
    "> 💡 **Tip**: Start with simple transformations and gradually add more complex ones. Monitor validation metrics to ensure augmentations help rather than hurt performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Define Data Transformations\n",
    "# ===================================\n",
    "\n",
    "from datamintapi.utils.visualization import show, draw_masks\n",
    "import albumentations as A\n",
    "from datamint import Dataset\n",
    "\n",
    "# Define the target image size for training\n",
    "# Smaller sizes train faster but may lose detail; larger sizes are more accurate but slower\n",
    "IMAGE_SIZE = (512, 512)\n",
    "\n",
    "# Create augmentation pipeline using Albumentations\n",
    "# Each transformation has a probability (p) of being applied\n",
    "transf = A.Compose([\n",
    "    # Randomly crop and resize to target size (scale: 33%-100% of original)\n",
    "    A.RandomResizedCrop(size=IMAGE_SIZE, scale=(0.33, 1.0), ratio=(0.9, 1.1), p=1.0),\n",
    "    \n",
    "    # Apply square symmetry (useful for anatomical structures)\n",
    "    A.SquareSymmetry(p=0.5),\n",
    "    \n",
    "    # Vary image appearance (brightness, contrast) - no hue/saturation for medical images\n",
    "    A.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.0, hue=0.0, p=0.5),\n",
    "    \n",
    "    # Add small amount of noise for robustness\n",
    "    A.GaussNoise(std_range=(0.01, 0.1), per_channel=False, p=0.2),\n",
    "])\n",
    "\n",
    "# Load dataset for visualization\n",
    "LOGGER.info(\"Loading dataset...\")\n",
    "D = Dataset(\n",
    "    project_name=PROJECT_NAME,\n",
    "    return_as_semantic_segmentation=True,    # Convert to pixel-level masks\n",
    "    semantic_seg_merge_strategy=\"union\",     # Combine overlapping annotations\n",
    "    return_frame_by_frame=True,              # Individual frames (not videos)\n",
    "    include_unannotated=False,               # Only annotated data\n",
    "    auto_update=False,                       # Don't check for updates (faster)\n",
    "    alb_transform=transf,                    # Apply our transformations\n",
    ")\n",
    "\n",
    "LOGGER.info(f\"✅ Dataset loaded: {len(D)} samples\")\n",
    "LOGGER.info(f\"Available segmentation labels: {D.segmentation_labels_set}\")\n",
    "\n",
    "# Visualize a sample with transformations applied\n",
    "item = D[0]\n",
    "LOGGER.info(f\"Image shape: {item['image'].shape}\")\n",
    "LOGGER.info(f\"Segmentation shape: {item['segmentations'].shape}\")\n",
    "\n",
    "# Display the image with overlay masks (excluding background at index 0)\n",
    "show(draw_masks(item['image'], item['segmentations'][1:], alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7cf4c",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "We'll now set up the training components:\n",
    "\n",
    "1. **DataModule**: Handles data loading and train/validation splits\n",
    "2. **Model**: Custom segmentation model (DeepLabV3 with ResNet50 backbone)\n",
    "3. **MLflow Integration**: Automatic experiment tracking and model versioning\n",
    "\n",
    "### Key Components Explained:\n",
    "\n",
    "- **DatamintDataModule**: Lightning-compatible data loader for Datamint datasets\n",
    "- **MyModel**: Custom model with multiple loss functions (CrossEntropy + GIOU + Focal)\n",
    "- **MLFlowModelCheckpoint**: Saves best models and logs them to MLflow automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7032c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Import Training Components\n",
    "# =================================\n",
    "\n",
    "from datamint.lightning import DatamintDataModule  # Lightning integration for Datamint\n",
    "from my_custom_model import MyModel                # Your custom segmentation model\n",
    "from datamint.mlflow.lightning.callbacks import MLFlowModelCheckpoint  # MLflow integration\n",
    "\n",
    "# Import torch for performance optimization\n",
    "import torch\n",
    "\n",
    "LOGGER.info(\"✅ All training components imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b308ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Configure Training Setup\n",
    "# ===============================\n",
    "\n",
    "# Define metadata that will be saved with the model\n",
    "# This helps with model deployment and inference later\n",
    "model_metadata = {\n",
    "    \"task_type\": \"semantic_segmentation\",\n",
    "    \"labels\": [\"background\"] + D.segmentation_labels_set,  # Include background as first label\n",
    "    \"need_gpu\": False,                    # Whether GPU is required for inference\n",
    "    \"automatic_preprocessing\": True       # Whether preprocessing is handled automatically\n",
    "}\n",
    "\n",
    "LOGGER.info(f\"Model will predict {len(model_metadata['labels'])} classes:\")\n",
    "for i, label in enumerate(model_metadata['labels']):\n",
    "    LOGGER.info(f\"  {i}: {label}\")\n",
    "\n",
    "# Configure model checkpointing with MLflow integration\n",
    "checkcb = MLFlowModelCheckpoint(\n",
    "    monitor=\"val/loss\",                   # Metric to monitor for best model\n",
    "    mode=\"min\",                          # Save model when monitored metric decreases\n",
    "    save_top_k=1,                        # Keep only the best model\n",
    "    filename=\"best\",                     # Checkpoint filename\n",
    "    save_weights_only=True,              # Save only model weights (not optimizer state)\n",
    "    register_model_name=PROJECT_NAME,    # Name for model registry\n",
    "    register_model_on='test',            # Register model after testing\n",
    "    code_paths=['my_custom_model.py'],   # Include source code with model\n",
    "    log_model_at_end_only=True,         # Log to MLflow only at the end (faster)\n",
    "    additional_metadata=model_metadata,  # Include our metadata\n",
    ")\n",
    "\n",
    "# Create MLflow logger for experiment tracking\n",
    "mlflow_logger = MLFlowLogger(experiment_name=PROJECT_NAME)\n",
    "LOGGER.info(f\"✅ MLflow experiment: {PROJECT_NAME}\")\n",
    "\n",
    "# Configure Lightning Trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,                       # Number of training epochs\n",
    "    logger=mlflow_logger,                # MLflow integration\n",
    "    precision='16-mixed',                # Use mixed precision for faster training\n",
    "    enable_model_summary=True,           # Show model architecture summary\n",
    "    enable_progress_bar=True,            # Show training progress\n",
    "    callbacks=[checkcb],                 # Include our checkpoint callback\n",
    "    num_sanity_val_steps=0,             # Skip validation sanity check\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "# Note: num_classes should match the number of segmentation classes (excluding background)\n",
    "num_classes = len(D.segmentation_labels_set)\n",
    "model = MyModel(num_classes=num_classes, learning_rate=3e-4)\n",
    "LOGGER.info(f\"✅ Model initialized for {num_classes} classes\")\n",
    "\n",
    "# Create data module with train/validation split\n",
    "dm = DatamintDataModule(\n",
    "    PROJECT_NAME,\n",
    "    batch_size=8,                        # Adjust based on your GPU memory\n",
    "    alb_transform=transf,                # Apply our transformations\n",
    "    num_workers=8,                       # Parallel data loading workers\n",
    "    # enable_video_cache=True,           # Uncomment to cache video frames\n",
    "    include_segmentation_names=['fibula', 'tibia', 'patella', 'femur']  # Specify which labels to include\n",
    ")\n",
    "\n",
    "LOGGER.info(\"✅ Training setup complete!\")\n",
    "LOGGER.info(f\"Batch size: {dm.batch_size}\")\n",
    "LOGGER.info(f\"Data workers: {dm.num_workers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f4fa7",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now we'll start the actual training process. This will:\n",
    "\n",
    "1. Automatically split your data into training and validation sets\n",
    "2. Train the model for the specified number of epochs\n",
    "3. Track metrics (loss, IoU, etc.) in MLflow\n",
    "4. Save the best model checkpoint based on validation loss\n",
    "\n",
    "### What to expect:\n",
    "- Training progress bar with loss values\n",
    "- Automatic logging of metrics to MLflow\n",
    "- Model checkpointing when validation improves\n",
    "\n",
    "> ⚠️ **Note**: Training time depends on your data size, model complexity, and hardware. Start with fewer epochs for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c174b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Start Training\n",
    "# =====================\n",
    "\n",
    "# Optimize matrix multiplication performance (PyTorch 2.0+)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "LOGGER.info(\"🚀 Starting training...\")\n",
    "LOGGER.info(\"This will automatically:\")\n",
    "LOGGER.info(\"  - Split data into train/validation sets\")\n",
    "LOGGER.info(\"  - Track metrics in MLflow\")\n",
    "LOGGER.info(\"  - Save the best model checkpoint\")\n",
    "LOGGER.info(\"  - Log model artifacts\")\n",
    "\n",
    "# Start training!\n",
    "trainer.fit(model, datamodule=dm)\n",
    "\n",
    "LOGGER.info(\"✅ Training completed!\")\n",
    "LOGGER.info(f\"Best model saved at: {checkcb.best_model_path}\")\n",
    "LOGGER.info(f\"MLflow run ID: {mlflow_logger.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4362ab",
   "metadata": {},
   "source": [
    "## Manual Model Logging (Optional)\n",
    "\n",
    "If you interrupted training or want to log the current model state manually, you can use the cell below. This is useful for:\n",
    "\n",
    "- Recovering from interrupted training sessions\n",
    "- Logging intermediate model states\n",
    "- Testing the logging functionality\n",
    "\n",
    "> 💡 **Tip**: This is only needed if automatic logging failed or was interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfeec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: Manual Model Logging (if needed)\n",
    "# =======================================\n",
    "\n",
    "# Uncomment the following line if you cancelled training but want to log the model anyway:\n",
    "# checkcb.log_model_to_mlflow(model, mlflow_logger.run_id)\n",
    "\n",
    "LOGGER.info(\"Manual logging skipped - model should have been logged automatically during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935cedc",
   "metadata": {},
   "source": [
    "## Update Model Metadata (Optional)\n",
    "\n",
    "You can add or update metadata after training is complete. This is useful for:\n",
    "\n",
    "- Adding deployment-specific information\n",
    "- Updating model descriptions\n",
    "- Including performance benchmarks\n",
    "- Specifying hardware requirements\n",
    "\n",
    "The metadata is stored as a JSON file alongside your model in MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9b009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: Update Model Metadata (Optional)\n",
    "# ========================================\n",
    "\n",
    "# Define updated or additional metadata\n",
    "model_metadata = {\n",
    "    \"task_type\": \"semantic_segmentation\",\n",
    "    \"labels\": [\"background\"] + D.segmentation_labels_set,\n",
    "    \"need_gpu\": False,\n",
    "    \"automatic_preprocessing\": True,\n",
    "}\n",
    "\n",
    "LOGGER.info(\"Updating model metadata...\")\n",
    "LOGGER.info(\"New metadata:\")\n",
    "for key, value in model_metadata.items():\n",
    "    LOGGER.info(f\"  {key}: {value}\")\n",
    "\n",
    "# Log the metadata (this will overwrite existing metadata)\n",
    "checkcb.log_additional_metadata(\n",
    "    trainer,              # Pass trainer (or mlflow_logger directly)\n",
    "    model_metadata       # Updated metadata dictionary\n",
    ")\n",
    "\n",
    "LOGGER.info(\"✅ Metadata updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a762f14",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "\n",
    "Now we'll evaluate the trained model on the test set. This will:\n",
    "\n",
    "1. Load the best model checkpoint (not the final training state)\n",
    "2. Run inference on the test/validation data\n",
    "3. Calculate final performance metrics\n",
    "4. Automatically register the model in MLflow Model Registry\n",
    "\n",
    "> 📊 **Important**: We test on the best checkpoint (lowest validation loss) rather than the final model state to get the most reliable performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add45982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: Test the Model\n",
    "# =====================\n",
    "\n",
    "LOGGER.info(\"🧪 Starting model testing...\")\n",
    "LOGGER.info(\"This will:\")\n",
    "LOGGER.info(\"  - Load the best model checkpoint\")\n",
    "LOGGER.info(\"  - Evaluate on test data\") \n",
    "LOGGER.info(\"  - Log final metrics to MLflow\")\n",
    "LOGGER.info(\"  - Register model in MLflow Model Registry\")\n",
    "\n",
    "# Test using the best model checkpoint\n",
    "test_results = trainer.test(\n",
    "    model,\n",
    "    ckpt_path=checkcb.best_model_path,    # Use best model, not last\n",
    "    datamodule=dm\n",
    ")\n",
    "\n",
    "LOGGER.info(\"✅ Testing completed!\")\n",
    "LOGGER.info(\"Final test metrics:\")\n",
    "for metric_name, value in test_results[0].items():\n",
    "    LOGGER.info(f\"  {metric_name}: {value:.4f}\")\n",
    "\n",
    "# Model registration happens automatically due to register_model_on='test'\n",
    "LOGGER.info(f\"🏆 Model registered in MLflow Model Registry as '{PROJECT_NAME}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67727687",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "Now let's use our trained model to make predictions on new data. This section demonstrates:\n",
    "\n",
    "1. Loading the trained model\n",
    "2. Setting up a prediction pipeline\n",
    "3. Running inference on test data\n",
    "4. Visualizing the results\n",
    "\n",
    "This is similar to how you would deploy the model in production.\n",
    "\n",
    "## Alternative Model Loading\n",
    "\n",
    "You can load models in several ways:\n",
    "- From checkpoint file: `trainer.predict(model, ckpt_path=\"path/to/checkpoint\")`\n",
    "- From MLflow registry: `mlflow.pytorch.load_model(\"models:/ModelName/Version\")`\n",
    "- From MLflow run: `mlflow.pytorch.load_model(\"runs:/run_id/model/artifact_path\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 10: Make Predictions\n",
    "# ========================\n",
    "\n",
    "LOGGER.info(\"🔮 Setting up prediction pipeline...\")\n",
    "\n",
    "# Create a new trainer for prediction (no training setup needed)\n",
    "pred_trainer = L.Trainer(\n",
    "    enable_model_summary=True,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "# Set up data module for prediction (same as before)\n",
    "pred_dm = DatamintDataModule(\n",
    "    PROJECT_NAME,\n",
    "    batch_size=8,\n",
    "    alb_transform=transf,\n",
    "    include_segmentation_names=['fibula', 'tibia', 'patella', 'femur']\n",
    ")\n",
    "\n",
    "LOGGER.info(\"Running predictions...\")\n",
    "LOGGER.info(\"Note: Using the model already in memory\")\n",
    "LOGGER.info(\"Alternative: Load from MLflow registry with:\")\n",
    "LOGGER.info(f\"  model = mlflow.pytorch.load_model('models:/{PROJECT_NAME}/latest')\")\n",
    "\n",
    "# Option 1: Use model already in memory\n",
    "preds = pred_trainer.predict(\n",
    "    model,\n",
    "    # ckpt_path=checkcb.best_model_path,  # Uncomment to load from checkpoint\n",
    "    datamodule=pred_dm\n",
    ")\n",
    "\n",
    "# Option 2: Load from MLflow Model Registry (commented out)\n",
    "# registered_model = mlflow.pytorch.load_model(f'models:/{PROJECT_NAME}/latest')\n",
    "# preds = pred_trainer.predict(registered_model, datamodule=pred_dm)\n",
    "\n",
    "LOGGER.info(f\"✅ Predictions completed!\")\n",
    "LOGGER.info(f\"Generated {len(preds)} batches of predictions\")\n",
    "LOGGER.info(f\"First batch shape: {preds[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b59db",
   "metadata": {},
   "source": [
    "## Visualizing Results\n",
    "\n",
    "Let's visualize the model's predictions to see how well it's performing. We'll:\n",
    "\n",
    "1. Convert model outputs to binary masks\n",
    "2. Load the corresponding input images\n",
    "3. Overlay predicted masks on the original images\n",
    "4. Display the results\n",
    "\n",
    "> 🎨 **Visualization Notes**: \n",
    "> - We exclude the background class (index 0) from visualization\n",
    "> - Different colors represent different anatomical structures\n",
    "> - Transparency (alpha) allows you to see both image and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b01d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 11: Visualize Predictions\n",
    "# ==============================\n",
    "predicted_mask = preds[0] > 0\n",
    "# plot mask\n",
    "for batch in dm.predict_dataloader():\n",
    "    imgs = batch['image']\n",
    "    break\n",
    "\n",
    "imgs_with_mask = []\n",
    "for im, pr in zip(imgs, predicted_mask):\n",
    "    imgs_with_mask.append(draw_masks(im, pr[1:]))  # pr[0] is the background\n",
    "show(imgs_with_mask, figsize=(16, 7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
